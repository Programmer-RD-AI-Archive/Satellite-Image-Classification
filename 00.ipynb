{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0b148c-d9be-4465-855b-1d58ee7ba0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import *\n",
    "import torch,torchvision\n",
    "from tqdm import tqdm\n",
    "device = 'cuda'\n",
    "PROJECT_NAME = 'Satellite-Image-Classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b088cb-720a-44c7-89c8-5d7b2ea93f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    idx = -1\n",
    "    labels = {}\n",
    "    data = []\n",
    "    for folder in tqdm(os.listdir('./data/')):\n",
    "        idx += 1\n",
    "        labels[folder] = idx\n",
    "        for file in os.listdir(f'./data/{folder}'):\n",
    "            file = f'./data/{folder}/{file}'\n",
    "            img = cv2.imread(file)\n",
    "            img = cv2.resize(img,(112,112))\n",
    "            data.append([img/255.0,labels[folder]])\n",
    "    np.random.shuffle(data)\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in data:\n",
    "        X.append(d[0])\n",
    "        y.append(d[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.0625)\n",
    "    return data,X,y,idx,labels,X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e48153-a210-44b7-8fbf-cc6aacd2046d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:00<00:00,  3.31it/s]"
     ]
    }
   ],
   "source": [
    "data,X,y,idx,labels,X_train,X_test,y_train,y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56426654-86bf-4d69-aa82-81ddddb4f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(np.array(X_train)).view(-1,3,112,112).to(device).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).view(-1,3,112,112).to(device).float()\n",
    "y_train = torch.from_numpy(np.array(y_train)).to(device)\n",
    "y_test = torch.from_numpy(np.array(y_test)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d7ae0-3d49-4338-89e9-4fd98a0723fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_r = {}\n",
    "for l_key,l_val in zip(labels.keys(),labels.values()):\n",
    "    labels_r[l_val] = l_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b508f-8106-4882-833c-d1ea8df94386",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ecc48a-f951-40a0-8127-19dc51ee81c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71009b0b-b323-473f-8c9d-4f61e7a8d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd8720-792c-4dea-95b4-dd7829cbd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.title(f'{labels_r[int(y_test[2])]}')\n",
    "# plt.imshow(X_test[2].view(112,112,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25521d53-980a-46e7-a0f8-ac8eb4c1ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()\n",
    "def get_accuracy(model,X,y):\n",
    "    total = -1\n",
    "    correct = -1\n",
    "    preds = model(X)\n",
    "    for y_batch,pred in zip(y,preds):\n",
    "        pred = torch.argmax(pred)\n",
    "        if y_batch == pred:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc\n",
    "def predict(model):\n",
    "    preds = []\n",
    "    for img in os.listdir('./test_data/'):\n",
    "        img = cv2.imread(f'./test_data/{img}')\n",
    "        img = cv2.resize(img,(112,112))\n",
    "        img = img / 255.0\n",
    "        pred = model(torch.from_numpy(np.array(img)).view(1,3,112,112).float().to(device))\n",
    "        pred = torch.argmax(pred)\n",
    "        plt.figure(figsize=(12,7))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'{labels[pred]}')\n",
    "        plt.savefig(f'./preds/{img}')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12815db0-846a-4aee-ad99-76dc6a91f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.max_pool2d = MaxPool2d((2,2),(2,2))\n",
    "        self.conv1 = Conv2d(3,6,(3,3))\n",
    "        self.conv1batchnorm = BatchNorm2d(6)\n",
    "        self.conv2 = Conv2d(6,12,(3,3))\n",
    "        self.conv2batchnorm = BatchNorm2d(12)\n",
    "        self.conv3 = Conv2d(12,24,(3,3))\n",
    "        self.conv3batchnorm = BatchNorm2d(24)\n",
    "        self.conv4 = Conv2d(24,48,(3,3))\n",
    "        self.conv4batchnorm = BatchNorm2d(48)\n",
    "        self.conv5 = Conv2d(48,96,(3,3))\n",
    "        self.conv5batchnorm = BatchNorm2d(96)\n",
    "        self.linear1 = Linear(96*1*1,128)\n",
    "        self.linear1batchnorm = BatchNorm1d(128)\n",
    "        self.linear2 = Linear(128,256)\n",
    "        self.linear2batchnorm = BatchNorm1d(256)\n",
    "        self.linear3 = Linear(256,512)\n",
    "        self.linear3batchnorm = BatchNorm1d(512)\n",
    "        self.linear4 = Linear(512,1024)\n",
    "        self.linear4batchnorm = BatchNorm1d(1024)\n",
    "        self.linear5 = Linear(1024,512)\n",
    "        self.linear5batchnorm = BatchNorm1d(512)\n",
    "        self.output = Linear(512,4)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = X\n",
    "        preds = self.activation(self.max_pool2d(self.conv1batchnorm(self.conv1(preds))))\n",
    "        preds = self.activation(self.max_pool2d(self.conv2batchnorm(self.conv2(preds))))\n",
    "        preds = self.activation(self.max_pool2d(self.conv3batchnorm(self.conv3(preds))))\n",
    "        preds = self.activation(self.max_pool2d(self.conv4batchnorm(self.conv4(preds))))\n",
    "        preds = self.activation(self.max_pool2d(self.conv5batchnorm(self.conv5(preds))))\n",
    "        preds = preds.view(-1,96*1*1)\n",
    "        preds = self.activation(self.linear1batchnorm(self.linear1(preds)))\n",
    "        preds = self.activation(self.linear2batchnorm(self.linear2(preds)))\n",
    "        preds = self.activation(self.linear3batchnorm(self.linear3(preds)))\n",
    "        preds = self.activation(self.linear4batchnorm(self.linear4(preds)))\n",
    "        preds = self.activation(self.linear5batchnorm(self.linear5(preds)))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38300860-1220-48e0-82c5-7faf185c8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85db0369-67b8-4b08-9721-6cd25095bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff480f-ab4e-447b-b822-5a88e3740266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaaa392-5655-479f-9344-37d46e3d5737",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558de5e-3d30-4a01-99d2-d0c0d530f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1fc8a-9879-4fa6-8b81-f7bd90f43beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4a1f5-a422-4f6f-9cea-f4ec917432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2eb2de-6f57-4b75-80fe-665517fdf6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "wandb.watch(model)\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),idx):\n",
    "        X_batch = X_train[i:i+batch_size].float().to(device).view(-1,3,112,112)\n",
    "        y_batch = y_train[i:i+batch_size].to(device)\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    wandb.log({'Loss':get_loss(model,X_train,y_train,criterion)})\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    wandb.log({'Acc':get_accuracy(model,X_train,y_train)})\n",
    "    wandb.log({'Val Acc':get_accuracy(model,X_test,y_test)})\n",
    "    predict(model)\n",
    "    for file in os.listdir('./preds/'):\n",
    "        wandb.log({f'Img/{file}':wandb.Image(cv2.imread(f'./preds/{file}'))})\n",
    "wandb.watch(model)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120d36a5-3245-4bd1-8b4d-5b3680836d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python373jvsc74a57bd0210f9608a45c0278a93c9e0b10db32a427986ab48cfc0d20c139811eb78c4bbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
